{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\anaconda3\\envs\\elsr-test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hebbian(nn.Module):\n",
    "    def __init__(self, input_size, output_size, learning_rate=0.001):\n",
    "        super(Hebbian, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size, bias=False)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def update_weights(self, x, y):\n",
    "        delta_w = torch.mm(x.t(), y) * self.learning_rate\n",
    "        delta_w /= torch.norm(delta_w) + 1e-8\n",
    "        self.linear.weight.data.add_(delta_w.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HebbianVgg19(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(HebbianVgg19, self).__init__()\n",
    "        vgg19 = torchvision.models.vgg19(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(vgg19.children())[:-1])\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "         \n",
    "        self.classifier = Hebbian(25088, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = self.classifier(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\anaconda3\\envs\\elsr-test\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\andre\\anaconda3\\envs\\elsr-test\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# CIFAR10\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# MNIST\n",
    "'''transform = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "     transforms.Grayscale(num_output_channels=3),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))\n",
    "     ])'''\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = HebbianVgg19().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:22<00:00,  1.55batch/s, accuracy=70.4, loss=2.62]\n",
      "  1%|          | 100/10000 [00:35<58:56,  2.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.616222856402397, Train Acc: 70.39. Test Loss: 2.107984893321991, Test Acc: 78.21000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:07<00:00,  1.63batch/s, accuracy=81.1, loss=1.69]\n",
      "  1%|          | 100/10000 [00:33<55:51,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 1.6891072260737419, Train Acc: 81.138. Test Loss: 2.329500181674957, Test Acc: 76.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:09<00:00,  1.62batch/s, accuracy=84.5, loss=1.36]\n",
      "  1%|          | 100/10000 [00:34<56:43,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 1.3563514048457146, Train Acc: 84.476. Test Loss: 2.6183029890060423, Test Acc: 78.25999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:09<00:00,  1.61batch/s, accuracy=87, loss=1.09]  \n",
      "  1%|          | 100/10000 [00:34<56:43,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 1.0940768716931344, Train Acc: 87.044. Test Loss: 2.0865228736400603, Test Acc: 81.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:12<00:00,  1.60batch/s, accuracy=88.6, loss=0.943]\n",
      "  1%|          | 100/10000 [00:35<59:09,  2.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.9426973187029362, Train Acc: 88.64999999999999. Test Loss: 2.0720505994558334, Test Acc: 82.21000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:21<00:00,  1.55batch/s, accuracy=90.1, loss=0.799]\n",
      "  1%|          | 100/10000 [00:36<1:00:09,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 0.7994300420507788, Train Acc: 90.106. Test Loss: 2.1199687603116035, Test Acc: 82.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:05<00:00,  1.64batch/s, accuracy=91.3, loss=0.694]\n",
      "  1%|          | 100/10000 [00:34<57:03,  2.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 0.6938239350989461, Train Acc: 91.328. Test Loss: 1.98048497736454, Test Acc: 83.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:10<00:00,  1.61batch/s, accuracy=92.1, loss=0.636]\n",
      "  1%|          | 100/10000 [00:34<56:39,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 0.6355333993807435, Train Acc: 92.144. Test Loss: 2.1381836956739426, Test Acc: 82.78999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:09<00:00,  1.62batch/s, accuracy=92.8, loss=0.565]\n",
      "  1%|          | 100/10000 [00:34<56:52,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 0.5648845233730971, Train Acc: 92.824. Test Loss: 2.310579543709755, Test Acc: 82.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:19<00:00,  1.57batch/s, accuracy=93.5, loss=0.484]\n",
      "  1%|          | 100/10000 [00:36<59:51,  2.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 0.4835554581945762, Train Acc: 93.54400000000001. Test Loss: 2.883821804523468, Test Acc: 81.93\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
    "        for i, data in enumerate(tepoch):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            net.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            output_grad = torch.zeros_like(outputs)\n",
    "            for idx, l in enumerate(labels):\n",
    "                output_grad[idx, l] = 1\n",
    "            output_grad -= nn.functional.softmax(outputs, dim=1)\n",
    "            output_grad /= output_grad.size(0)\n",
    "\n",
    "            net.classifier.update_weights(net.features(inputs).view(inputs.size(0), -1).detach(), output_grad.detach())\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            tepoch.set_postfix(loss=running_loss / (i + 1), accuracy=correct / total * 100)\n",
    "\n",
    "    net.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad(), tqdm(total=len(testloader)) as pbar:\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Train Loss: {running_loss / (i + 1)}, Train Acc: {correct / total * 100}. Test Loss: {test_loss / len(testloader)}, Test Acc: {test_correct / test_total * 100}\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elsr-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
