{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p align=\"center\">\n",
    " <img src=\".../../img/pseudo-attention.svg\" width=\"66%\" >\n",
    "</p>\n",
    "\n",
    "\n",
    "image: ../../img/pseudo-attention.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "####################################################################\n",
    "\n",
    "def evaluate(device, model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "####################################################################\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    accuracy = 100. * correct / total\n",
    "    return train_loss, accuracy\n",
    "\n",
    "################################################################\n",
    "\n",
    "def head_batched_attention_mechanism(Q, K, V):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Q: (batch_size, num_heads, num_layer, activation_size)\n",
    "        K: (batch_size, num_heads, num_layer, activation_size)\n",
    "        V: (batch_size, num_heads, activation_size, 1) # activations in the current layer\n",
    "\n",
    "    Returns:\n",
    "        attention: (batch_size, num_heads, activation_size)\n",
    "\n",
    "        # attention mechanism\n",
    "        # # (batch_size, num_heads, activation_size, activation_size)\n",
    "        # attention = torch.matmul(Q, K.transpose(-1,-2))\n",
    "        # attention = attention / torch.sqrt(torch.tensor(activation_size).float())\n",
    "\n",
    "        # # (batch_size, num_heads, activation_size, 1)\n",
    "        # attention = nn.Softmax(dim=-1)(attention)\n",
    "\n",
    "        # # (batch_size, num_heads, activation_size, 1)\n",
    "        # attention = torch.matmul(attention, V)\n",
    "\n",
    "        # # (batch_size, num_heads, activation_size)\n",
    "        # attention = attention.squeeze(-1)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return (nn.Softmax(dim=-1)(\n",
    "                torch.matmul( \n",
    "                            Q.transpose(-1,-2) , \n",
    "                            K\n",
    "                )/torch.sqrt(torch.tensor(8))    \n",
    "            ) @ V).squeeze(-1)\n",
    "\n",
    "\n",
    "################################################################\n",
    "\n",
    "\n",
    "class LinW_Attention_Module(nn.Module):\n",
    "    def __init__(self, dim_emb, n_head) -> None:\n",
    "        super(LinW_Attention_Module, self).__init__()\n",
    "\n",
    "        assert dim_emb % n_head == 0, 'dim_emb must be divisible by n_head'\n",
    "\n",
    "        self.dim_emb = dim_emb\n",
    "        self.n_head = n_head\n",
    "\n",
    "        self.W_Q = nn.Linear(dim_emb, dim_emb)\n",
    "        self.W_K = nn.Linear(dim_emb, dim_emb)\n",
    "        self.W_V = nn.Linear(dim_emb, dim_emb)\n",
    "\n",
    "        self.W_O = nn.Linear(dim_emb*n_head, dim_emb)\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        # get the shape of the input\n",
    "        batch_size, activation_size, activation_size = Q.size()\n",
    "        \n",
    "        # check the device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # move to device\n",
    "        Q.to(device)\n",
    "        K.to(device)\n",
    "        V.to(device)\n",
    "        \n",
    "        # reshape Q, K, V\n",
    "        # parallelize over the number of heads\n",
    "        # (batch_size, num_heads, num_layer, activation_size)\n",
    "        Q = torch.stack([Q for _ in range(self.n_head)], 1)\n",
    "        K = torch.stack([K for _ in range(self.n_head)], 1)\n",
    "        V = torch.stack([V for _ in range(self.n_head)], 1)\n",
    "\n",
    "        # apply linear transformation\n",
    "        Q = self.W_Q(Q)\n",
    "        K = self.W_K(K)\n",
    "        V = self.W_V(V).reshape(batch_size, self.n_head, activation_size, 1)\n",
    "        \n",
    "        # apply attention mechanism\n",
    "        out_attention = head_batched_attention_mechanism(Q, K, V).reshape(batch_size, self.n_head*activation_size)\n",
    "\n",
    "        # apply linear transformation\n",
    "        return self.W_O(out_attention)\n",
    "\n",
    "\n",
    "####################################################################\n",
    "\n",
    "def get_activations_per_object(activations):\n",
    "    \"\"\" Get the activations for each object per layer\n",
    "\n",
    "    Args:\n",
    "        activations (torch.Tensor): shape (num_layers, batch_size, number_activations)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: shape (nr_object, num_layers, activation_for_each_layer)\n",
    "\n",
    "    \"\"\"\n",
    "    return torch.stack([activations[:,i,:] for i in range(activations.shape[1])])\n",
    "\n",
    "####################################################################\n",
    "\n",
    "def get_layer_activations(activations):\n",
    "    \"\"\" Get the activations for each layer for each sample\n",
    "\n",
    "    Args:\n",
    "        activations (torch.Tensor): shape (batch_size, number_activations)\n",
    "        batch_size (int): batch size\n",
    "        number_activations (int): number of activations\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: shape (nr_object, num_layers, activation_for_each_layer)\n",
    "\n",
    "    \"\"\"\n",
    "    return get_activations_per_object(torch.stack(activations))\n",
    "\n",
    "####################################################################\n",
    "\n",
    "\n",
    "class MLPWD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPWD, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = nn.Linear(784, 8)\n",
    "        self.l2 = LinW(in_features=8, out_features=8, depth=0)\n",
    "        self.l3 = LinW(in_features=8, out_features=8, depth=1, layers=[self.l2])\n",
    "        self.l4 = nn.Linear(8, 10)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.layers = [self.l2, self.l3]\n",
    "\n",
    "    def forward(self, x):\n",
    "        repr = []\n",
    "        x = self.flatten(x)\n",
    "        x = self.l1(x)\n",
    "        repr.append(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.l2(x, repr)\n",
    "        repr.append(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.gelu(self.l3(x, repr))\n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.layers[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.layers)\n",
    "    \n",
    "\n",
    "class LinW(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, depth, layers=[]):\n",
    "        super(LinW, self).__init__(in_features=in_features, out_features=out_features)\n",
    "        self.depth = depth\n",
    "        self.layers = layers[:self.depth] if len(layers)>0 else layers\n",
    "        self.mha = LinW_Attention_Module(in_features, 4)\n",
    "\n",
    "    def forward(self, input, activations=[]):\n",
    "        activations = get_layer_activations(activations)\n",
    "        return F.linear(self.mha(activations, activations, input), self.weight, self.bias)\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = MLPWD().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "print(\"LinW layers:\", \"\\n\".join([f\"Depth {model[i].depth}: {model[i]}\" for i in range(len(model))]), sep=\"\\n\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_accuracy = evaluate(device, model, test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.2f}%, Test accuracy: {test_accuracy:.2f}%')\n",
    "    lr_scheduler.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3163cfb8aa3549ad3f5400bc3427ee7a4002d2a0d6d7ead52f641c6a7636395"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
