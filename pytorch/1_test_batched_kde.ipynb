{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    accuracy = 100. * correct / total\n",
    "    return train_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def evaluate(device, model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinW layers:\n",
      "\n",
      "Depth 0: LinW(in_features=64, out_features=64, bias=True)\n",
      "Depth 1: LinW(in_features=64, out_features=64, bias=True)\n",
      "Epoch 1/10, Training Loss: 1.6687, Training Accuracy: 39.01%, Test accuracy: 49.06%\n",
      "Epoch 2/10, Training Loss: 1.3445, Training Accuracy: 51.48%, Test accuracy: 53.64%\n",
      "Epoch 3/10, Training Loss: 1.2649, Training Accuracy: 54.51%, Test accuracy: 56.10%\n",
      "Epoch 4/10, Training Loss: 1.2258, Training Accuracy: 55.48%, Test accuracy: 57.01%\n",
      "Epoch 5/10, Training Loss: 1.1836, Training Accuracy: 56.70%, Test accuracy: 56.09%\n",
      "Epoch 6/10, Training Loss: 1.1564, Training Accuracy: 57.52%, Test accuracy: 57.70%\n",
      "Epoch 7/10, Training Loss: 1.1321, Training Accuracy: 58.13%, Test accuracy: 57.77%\n",
      "Epoch 8/10, Training Loss: 1.1127, Training Accuracy: 59.04%, Test accuracy: 59.86%\n",
      "Epoch 9/10, Training Loss: 1.0984, Training Accuracy: 59.62%, Test accuracy: 59.93%\n",
      "Epoch 10/10, Training Loss: 1.0898, Training Accuracy: 59.99%, Test accuracy: 61.62%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "def extract_activations_layers(layers):\n",
    "    \"\"\" Extract for each layer the activations\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (layer_activation, batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.array([np.array([np.array(h) for h in l]) for l in layers])\n",
    "\n",
    "def extract_activations_per_sample(layers, mask = False):\n",
    "    \"\"\" Extract for each sample the activations \n",
    "    for each layer and store them in a list.\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    if mask == True:\n",
    "        # mask the activations to remove zeros\n",
    "        mask = layers != 0\n",
    "        layers = [[np.array(h[m]) for h, m in zip(l,sm)] \n",
    "                for l, sm in zip(layers, mask)]\n",
    "        \n",
    "    return np.array([layers[:,i,:].flatten().reshape(-1, 1) for i in range(layers.shape[1])])\n",
    "\n",
    "\n",
    "def get_sampled_activations(activations, bandwidth = 0.2):\n",
    "    \"\"\" Sample the activations using KDE\n",
    "\n",
    "    Args:\n",
    "        activations (np.array): shape (batch_size, number_of_activations)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.from_numpy(np.array([KernelDensity(kernel=\"gaussian\", bandwidth=bandwidth).fit(a).sample([64]) for a in activations], dtype=\"float32\")).squeeze(2)\n",
    "\n",
    "def wd(layers: list()):\n",
    "    \"\"\" Compute the weight decay for each layer\n",
    "\n",
    "    Args:\n",
    "        layers (list): list of layers\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor: weight decay\n",
    "\n",
    "    \"\"\"\n",
    "    return get_sampled_activations(\n",
    "                list(\n",
    "                    extract_activations_per_sample(\n",
    "                            extract_activations_layers(layers), \n",
    "                            mask=False\n",
    "                        )\n",
    "                ), \n",
    "                bandwidth=0.2\n",
    "            )\n",
    "\n",
    "class MLPWD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPWD, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = nn.Linear(784, 64)\n",
    "        self.l2 = LinW(in_features=64, out_features=64, depth=0)\n",
    "        self.l3 = LinW(in_features=64, out_features=64, depth=1, layers=[self.l2])\n",
    "        self.l4 = nn.Linear(64, 10)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.layers = [self.l2, self.l3]\n",
    "\n",
    "    def forward(self, x):\n",
    "        repr = []\n",
    "        x = self.flatten(x)\n",
    "        x = self.gelu(self.l1(x))\n",
    "        repr.append(x.detach().cpu().numpy())\n",
    "        x = self.gelu(self.l2(x, repr))\n",
    "        repr.append(x.detach().cpu().numpy())\n",
    "        x = self.gelu(self.l3(x, repr))\n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.layers[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.layers)\n",
    "    \n",
    "\n",
    "class LinW(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, depth, layers=[]):\n",
    "        super(LinW, self).__init__(in_features=in_features, out_features=out_features)\n",
    "        self.depth = depth\n",
    "        self.layers = layers[:self.depth] if len(layers)>0 else layers\n",
    "\n",
    "    def forward(self, input, prev=[]):\n",
    "        # weight_decay = wd(prev)\n",
    "        # weight = self.weight * weight_decay.to('cuda:0')\n",
    "        # return F.linear(input, weight, self.bias)\n",
    "        # print(wd(prev).shape)\n",
    "        return F.linear(input* wd(prev).to('cuda:0'), self.weight, self.bias)\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = MLPWD().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "print(\"LinW layers:\", \"\\n\".join([f\"Depth {model[i].depth}: {model[i]}\" for i in range(len(model))]), sep=\"\\n\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_accuracy = evaluate(device, model, test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.2f}%, Test accuracy: {test_accuracy:.2f}%')\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinW layers:\n",
      "\n",
      "Depth 0: LinW(in_features=64, out_features=64, bias=True)\n",
      "Depth 1: LinW(in_features=64, out_features=64, bias=True)\n",
      "Epoch 1/10, Training Loss: 2.3016, Training Accuracy: 11.37%, Test accuracy: 11.24%\n",
      "Epoch 2/10, Training Loss: 2.2997, Training Accuracy: 11.81%, Test accuracy: 11.93%\n",
      "Epoch 3/10, Training Loss: 2.2986, Training Accuracy: 12.07%, Test accuracy: 12.17%\n",
      "Epoch 4/10, Training Loss: 2.2990, Training Accuracy: 11.91%, Test accuracy: 11.67%\n",
      "Epoch 5/10, Training Loss: 2.2993, Training Accuracy: 11.83%, Test accuracy: 12.25%\n",
      "Epoch 6/10, Training Loss: 2.2988, Training Accuracy: 12.08%, Test accuracy: 12.16%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 142\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLinW layers:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDepth \u001b[39m\u001b[39m{\u001b[39;00mmodel[i]\u001b[39m.\u001b[39mdepth\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mmodel[i]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(model))]), sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m--> 142\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train(model, train_loader, criterion, optimizer, device)\n\u001b[1;32m    143\u001b[0m     test_accuracy \u001b[39m=\u001b[39m evaluate(device, model, test_loader)\n\u001b[1;32m    144\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mEPOCHS\u001b[39m}\u001b[39;00m\u001b[39m, Training Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Training Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%, Test accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_accuracy\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     11\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 12\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     13\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m images\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m _, predicted \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/jax/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:69\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     68\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/jax/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/jax/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/mambaforge/envs/jax/lib/python3.11/site-packages/torch/optim/adamw.py:171\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    158\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    161\u001b[0m         group,\n\u001b[1;32m    162\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m         state_steps,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m     adamw(\n\u001b[1;32m    172\u001b[0m         params_with_grad,\n\u001b[1;32m    173\u001b[0m         grads,\n\u001b[1;32m    174\u001b[0m         exp_avgs,\n\u001b[1;32m    175\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    176\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    177\u001b[0m         state_steps,\n\u001b[1;32m    178\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    179\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    180\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    181\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    182\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    183\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    184\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    185\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    186\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    187\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    188\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    189\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    190\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/mambaforge/envs/jax/lib/python3.11/site-packages/torch/optim/adamw.py:321\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 321\u001b[0m func(\n\u001b[1;32m    322\u001b[0m     params,\n\u001b[1;32m    323\u001b[0m     grads,\n\u001b[1;32m    324\u001b[0m     exp_avgs,\n\u001b[1;32m    325\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    326\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    327\u001b[0m     state_steps,\n\u001b[1;32m    328\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    329\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    330\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    331\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    332\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    333\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    334\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    335\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    336\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    337\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    338\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[1;32m    339\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/jax/lib/python3.11/site-packages/torch/optim/adamw.py:493\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    490\u001b[0m device_params \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mview_as_real(x) \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(x) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m device_params]\n\u001b[1;32m    492\u001b[0m \u001b[39m# update steps\u001b[39;00m\n\u001b[0;32m--> 493\u001b[0m torch\u001b[39m.\u001b[39;49m_foreach_add_(device_state_steps, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    495\u001b[0m \u001b[39m# Perform stepweight decay\u001b[39;00m\n\u001b[1;32m    496\u001b[0m torch\u001b[39m.\u001b[39m_foreach_mul_(device_params, \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m lr \u001b[39m*\u001b[39m weight_decay)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "def extract_activations_layers(layers):\n",
    "    \"\"\" Extract for each layer the activations\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (layer_activation, batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.array([np.array([np.array(h) for h in l]) for l in layers])\n",
    "\n",
    "def extract_activations_per_sample(layers, mask = False):\n",
    "    \"\"\" Extract for each sample the activations \n",
    "    for each layer and store them in a list.\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    if mask == True:\n",
    "        # mask the activations to remove zeros\n",
    "        mask = layers != 0\n",
    "        layers = [[np.array(h[m]) for h, m in zip(l,sm)] \n",
    "                for l, sm in zip(layers, mask)]\n",
    "        \n",
    "    return np.array([layers[:,i,:].flatten().reshape(-1, 1) for i in range(layers.shape[1])])\n",
    "\n",
    "\n",
    "def get_sampled_activations(activations, bandwidth = 0.2):\n",
    "    \"\"\" Sample the activations using KDE\n",
    "\n",
    "    Args:\n",
    "        activations (np.array): shape (batch_size, number_of_activations)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.from_numpy(np.array([KernelDensity(kernel=\"gaussian\", bandwidth=bandwidth).fit(a).sample([64]) for a in activations], dtype=\"float32\")).squeeze(2)\n",
    "\n",
    "def wd(layers: list()):\n",
    "    \"\"\" Compute the weight decay for each layer\n",
    "\n",
    "    Args:\n",
    "        layers (list): list of layers\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor: weight decay\n",
    "\n",
    "    \"\"\"\n",
    "    return get_sampled_activations(\n",
    "                list(\n",
    "                    extract_activations_per_sample(\n",
    "                            extract_activations_layers(layers), \n",
    "                            mask=False\n",
    "                        )\n",
    "                ), \n",
    "                bandwidth=0.2\n",
    "            )\n",
    "\n",
    "class MLPWD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPWD, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = nn.Linear(784, 64)\n",
    "        self.l2 = LinW(in_features=64, out_features=64, depth=0)\n",
    "        self.l3 = LinW(in_features=64, out_features=64, depth=1, layers=[self.l2])\n",
    "        self.l4 = nn.Linear(64, 10)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.layers = [self.l2, self.l3]\n",
    "\n",
    "    def forward(self, x):\n",
    "        repr = []\n",
    "        x = self.flatten(x)\n",
    "        x = self.gelu(self.l1(x))\n",
    "        repr.append(x.detach().cpu().numpy())\n",
    "        x = self.gelu(self.l2(x, repr))\n",
    "        repr.append(x.detach().cpu().numpy())\n",
    "        x = self.gelu(self.l3(x, repr))\n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.layers[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.layers)\n",
    "    \n",
    "\n",
    "class LinW(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, depth, layers=[]):\n",
    "        super(LinW, self).__init__(in_features=in_features, out_features=out_features)\n",
    "        self.depth = depth\n",
    "        self.layers = layers[:self.depth] if len(layers)>0 else layers\n",
    "\n",
    "    def forward(self, input, prev=[]):\n",
    "        # weight_decay = wd(prev)\n",
    "        # weight = self.weight * weight_decay.to('cuda:0')\n",
    "        # return F.linear(input, weight, self.bias)\n",
    "        # print(wd(prev).shape)\n",
    "        return F.linear(wd(prev).to('cuda:0'), self.weight, self.bias)\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = MLPWD().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "print(\"LinW layers:\", \"\\n\".join([f\"Depth {model[i].depth}: {model[i]}\" for i in range(len(model))]), sep=\"\\n\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_accuracy = evaluate(device, model, test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.2f}%, Test accuracy: {test_accuracy:.2f}%')\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinW layers:\n",
      "\n",
      "Depth 0: LinW(in_features=64, out_features=64, bias=True)\n",
      "Depth 1: LinW(in_features=64, out_features=64, bias=True)\n",
      "Epoch 1/10, Training Loss: 0.3766, Training Accuracy: 88.75%, Test accuracy: 93.53%\n",
      "Epoch 2/10, Training Loss: 0.1644, Training Accuracy: 95.06%, Test accuracy: 95.93%\n",
      "Epoch 3/10, Training Loss: 0.1139, Training Accuracy: 96.59%, Test accuracy: 96.23%\n",
      "Epoch 4/10, Training Loss: 0.0916, Training Accuracy: 97.22%, Test accuracy: 96.74%\n",
      "Epoch 5/10, Training Loss: 0.0743, Training Accuracy: 97.71%, Test accuracy: 97.07%\n",
      "Epoch 6/10, Training Loss: 0.0606, Training Accuracy: 98.08%, Test accuracy: 96.70%\n",
      "Epoch 7/10, Training Loss: 0.0522, Training Accuracy: 98.39%, Test accuracy: 96.80%\n",
      "Epoch 8/10, Training Loss: 0.0446, Training Accuracy: 98.58%, Test accuracy: 97.38%\n",
      "Epoch 9/10, Training Loss: 0.0388, Training Accuracy: 98.82%, Test accuracy: 97.44%\n",
      "Epoch 10/10, Training Loss: 0.0337, Training Accuracy: 98.93%, Test accuracy: 97.44%\n"
     ]
    }
   ],
   "source": [
    "\"\"\" In this experiment we introduce a mutation magnitude over the \n",
    "activations in the intermediate layers. Since the activations mutate\n",
    "we still introduce an additional dynamic weight that play an important\n",
    "role in the training process to update the weights of the network.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def extract_activations_layers(layers):\n",
    "    \"\"\" Extract for each layer the activations\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (layer_activation, batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.array([np.array([np.array(h) for h in l]) for l in layers])\n",
    "\n",
    "def extract_activations_per_sample(layers, mask = False):\n",
    "    \"\"\" Extract for each sample the activations \n",
    "    for each layer and store them in a list.\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    if mask == True:\n",
    "        # mask the activations to remove zeros\n",
    "        mask = layers != 0\n",
    "        layers = [[np.array(h[m]) for h, m in zip(l,sm)] \n",
    "                for l, sm in zip(layers, mask)]\n",
    "        \n",
    "    return np.array([layers[:,i,:].flatten().reshape(-1, 1) for i in range(layers.shape[1])])\n",
    "\n",
    "\n",
    "def get_sampled_activations(activations, bandwidth = 0.2):\n",
    "    \"\"\" Sample the activations using KDE\n",
    "\n",
    "    Args:\n",
    "        activations (np.array): shape (batch_size, number_of_activations)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.from_numpy(np.array([KernelDensity(kernel=\"gaussian\", bandwidth=bandwidth).fit(a).sample([64]) for a in activations], dtype=\"float32\")).squeeze(2)\n",
    "\n",
    "def wd(layers: list()):\n",
    "    \"\"\" Compute the weight decay for each layer\n",
    "\n",
    "    Args:\n",
    "        layers (list): list of layers\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor: weight decay\n",
    "\n",
    "    \"\"\"\n",
    "    return get_sampled_activations(\n",
    "                list(\n",
    "                    extract_activations_per_sample(\n",
    "                            extract_activations_layers(layers), \n",
    "                            mask=False\n",
    "                        )\n",
    "                ), \n",
    "                bandwidth=0.2\n",
    "            )\n",
    "\n",
    "class MLPWD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPWD, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = nn.Linear(784, 64)\n",
    "        self.l2 = LinW(in_features=64, out_features=64, depth=0)\n",
    "        self.l3 = LinW(in_features=64, out_features=64, depth=1, layers=[self.l2])\n",
    "        self.l4 = nn.Linear(64, 10)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.layers = [self.l2, self.l3]\n",
    "\n",
    "    def forward(self, x):\n",
    "        repr = []\n",
    "        x = self.flatten(x)\n",
    "        x = self.gelu(self.l1(x))\n",
    "        repr.append(x.detach().cpu().numpy())\n",
    "        x = self.gelu(self.l2(x, repr))\n",
    "        repr.append(x.detach().cpu().numpy())\n",
    "        x = self.gelu(self.l3(x, repr))\n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.layers[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.layers)\n",
    "    \n",
    "\n",
    "class LinW(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, depth, layers=[]):\n",
    "        super(LinW, self).__init__(in_features=in_features, out_features=out_features)\n",
    "        self.depth = depth\n",
    "        self.layers = layers[:self.depth] if len(layers)>0 else layers\n",
    "\n",
    "    def forward(self, input, prev=[]):\n",
    "        # weight_decay = wd(prev)\n",
    "        # weight = self.weight * weight_decay.to('cuda:0')\n",
    "        # return F.linear(input, weight, self.bias)\n",
    "        # print(wd(prev).shape)\n",
    "        return F.linear(input*random.uniform(0.99,1.09), self.weight, self.bias)\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = MLPWD().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "print(\"LinW layers:\", \"\\n\".join([f\"Depth {model[i].depth}: {model[i]}\" for i in range(len(model))]), sep=\"\\n\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_accuracy = evaluate(device, model, test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.2f}%, Test accuracy: {test_accuracy:.2f}%')\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinW layers:\n",
      "\n",
      "Depth 0: LinW(in_features=64, out_features=64, bias=True)\n",
      "Depth 1: LinW(in_features=64, out_features=64, bias=True)\n",
      "Epoch 1/10, Training Loss: 0.7291, Training Accuracy: 75.94%, Test accuracy: 82.01%\n",
      "Epoch 2/10, Training Loss: 0.5565, Training Accuracy: 82.27%, Test accuracy: 83.00%\n",
      "Epoch 3/10, Training Loss: 0.5347, Training Accuracy: 82.81%, Test accuracy: 83.62%\n",
      "Epoch 4/10, Training Loss: 0.5326, Training Accuracy: 83.13%, Test accuracy: 83.76%\n",
      "Epoch 5/10, Training Loss: 0.5273, Training Accuracy: 83.41%, Test accuracy: 82.78%\n",
      "Epoch 6/10, Training Loss: 0.5334, Training Accuracy: 83.11%, Test accuracy: 82.91%\n",
      "Epoch 7/10, Training Loss: 0.5336, Training Accuracy: 83.21%, Test accuracy: 84.01%\n",
      "Epoch 8/10, Training Loss: 0.5358, Training Accuracy: 83.08%, Test accuracy: 83.01%\n",
      "Epoch 9/10, Training Loss: 0.5353, Training Accuracy: 83.09%, Test accuracy: 82.71%\n",
      "Epoch 10/10, Training Loss: 0.5376, Training Accuracy: 83.33%, Test accuracy: 83.13%\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Here insted of multiply I sum the sampled activations\n",
    "of the previous layers on the inputs.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "def extract_activations_layers(layers):\n",
    "    \"\"\" Extract for each layer the activations\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (layer_activation, batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.array([np.array([np.array(h) for h in l]) for l in layers])\n",
    "\n",
    "def extract_activations_per_sample(layers, mask = False):\n",
    "    \"\"\" Extract for each sample the activations \n",
    "    for each layer and store them in a list.\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    if mask == True:\n",
    "        # mask the activations to remove zeros\n",
    "        mask = layers != 0\n",
    "        layers = [[np.array(h[m]) for h, m in zip(l,sm)] \n",
    "                for l, sm in zip(layers, mask)]\n",
    "        \n",
    "    return np.array([layers[:,i,:].flatten().reshape(-1, 1) for i in range(layers.shape[1])])\n",
    "\n",
    "\n",
    "def get_sampled_activations(activations, bandwidth = 0.2):\n",
    "    \"\"\" Sample the activations using KDE\n",
    "\n",
    "    Args:\n",
    "        activations (np.array): shape (batch_size, number_of_activations)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.from_numpy(np.array([KernelDensity(kernel=\"gaussian\", bandwidth=bandwidth).fit(a).sample([64]) for a in activations], dtype=\"float32\")).squeeze(2)\n",
    "\n",
    "def wd(layers: list()):\n",
    "    \"\"\" Compute the weight decay for each layer\n",
    "\n",
    "    Args:\n",
    "        layers (list): list of layers\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor: weight decay\n",
    "\n",
    "    \"\"\"\n",
    "    return get_sampled_activations(\n",
    "                list(\n",
    "                    extract_activations_per_sample(\n",
    "                            extract_activations_layers(layers), \n",
    "                            mask=False\n",
    "                        )\n",
    "                ), \n",
    "                bandwidth=0.2\n",
    "            )\n",
    "\n",
    "class MLPWD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPWD, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = nn.Linear(784, 64)\n",
    "        self.l2 = LinW(in_features=64, out_features=64, depth=0)\n",
    "        self.l3 = LinW(in_features=64, out_features=64, depth=1, layers=[self.l2])\n",
    "        self.l4 = nn.Linear(64, 10)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.layers = [self.l2, self.l3]\n",
    "\n",
    "    def forward(self, x):\n",
    "        repr = []\n",
    "        x = self.flatten(x)\n",
    "        x = self.gelu(self.l1(x))\n",
    "        repr.append(x.detach().cpu().numpy())\n",
    "        x = self.gelu(self.l2(x, repr))\n",
    "        repr.append(x.detach().cpu().numpy())\n",
    "        x = self.gelu(self.l3(x, repr))\n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.layers[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.layers)\n",
    "    \n",
    "\n",
    "class LinW(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, depth, layers=[]):\n",
    "        super(LinW, self).__init__(in_features=in_features, out_features=out_features)\n",
    "        self.depth = depth\n",
    "        self.layers = layers[:self.depth] if len(layers)>0 else layers\n",
    "\n",
    "    def forward(self, input, prev=[]):\n",
    "        # weight_decay = wd(prev)\n",
    "        # weight = self.weight * weight_decay.to('cuda:0')\n",
    "        # return F.linear(input, weight, self.bias)\n",
    "        return F.linear(input+wd(prev).to('cuda:0'), self.weight, self.bias)\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = MLPWD().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "print(\"LinW layers:\", \"\\n\".join([f\"Depth {model[i].depth}: {model[i]}\" for i in range(len(model))]), sep=\"\\n\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_accuracy = evaluate(device, model, test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.2f}%, Test accuracy: {test_accuracy:.2f}%')\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "def extract_activations_layers(layers):\n",
    "    \"\"\" Extract for each layer the activations\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (layer_activation, batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.array([np.array([np.array(h) for h in l]) for l in layers])\n",
    "\n",
    "def extract_activations_per_sample(layers, mask = False):\n",
    "    \"\"\" Extract for each sample the activations \n",
    "    for each layer and store them in a list.\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    if mask == True:\n",
    "        # mask the activations to remove zeros\n",
    "        mask = layers != 0\n",
    "        layers = [[np.array(h[m]) for h, m in zip(l,sm)] \n",
    "                for l, sm in zip(layers, mask)]\n",
    "        \n",
    "    return np.array([layers[:,i,:].flatten().reshape(-1, 1) for i in range(layers.shape[1])])\n",
    "\n",
    "\n",
    "def get_sampled_activations(activations, bandwidth = 0.2):\n",
    "    \"\"\" Sample the activations using KDE\n",
    "\n",
    "    Args:\n",
    "        activations (np.array): shape (batch_size, number_of_activations)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.from_numpy(np.array([KernelDensity(kernel=\"gaussian\", bandwidth=bandwidth).fit(a).sample([64]) for a in activations], dtype=\"float32\")).squeeze(2)\n",
    "\n",
    "def wd(layers: list()):\n",
    "    \"\"\" Compute the weight decay for each layer\n",
    "\n",
    "    Args:\n",
    "        layers (list): list of layers\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor: weight decay\n",
    "\n",
    "    \"\"\"\n",
    "    return get_sampled_activations(\n",
    "                list(\n",
    "                    extract_activations_per_sample(\n",
    "                            extract_activations_layers(layers), \n",
    "                            mask=False\n",
    "                        )\n",
    "                ), \n",
    "                bandwidth=0.2\n",
    "            )\n",
    "\n",
    "class MLPWD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPWD, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = nn.Linear(3072, 64)\n",
    "        self.l2 = LinW(in_features=64, out_features=64, depth=0)\n",
    "        self.l3 = LinW(in_features=64, out_features=64, depth=1, layers=[self.l2])\n",
    "        self.l4 = nn.Linear(64, 10)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.layers = [self.l2, self.l3]\n",
    "\n",
    "    def forward(self, x):\n",
    "        repr = []\n",
    "        x = self.flatten(x)\n",
    "        x = self.gelu(self.l1(x))\n",
    "        repr.append(x.detach().cpu().numpy())\n",
    "        x = self.gelu(self.l2(x, repr))\n",
    "        repr.append(x.detach().cpu().numpy())\n",
    "        x = self.gelu(self.l3(x, repr))\n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.layers[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.layers)\n",
    "    \n",
    "\n",
    "class LinW(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, depth, layers=[]):\n",
    "        super(LinW, self).__init__(in_features=in_features, out_features=out_features)\n",
    "        self.depth = depth\n",
    "        self.layers = layers[:self.depth] if len(layers)>0 else layers\n",
    "\n",
    "    def forward(self, input, prev=[]):\n",
    "        # weight_decay = wd(prev)\n",
    "        # weight = self.weight * weight_decay.to('cuda:0')\n",
    "        # return F.linear(input, weight, self.bias)\n",
    "        print(wd(prev).shape)\n",
    "        return F.linear(input, self.weight* wd(prev).to('cuda:0'), self.bias)\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = MLPWD().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "print(\"LinW layers:\", \"\\n\".join([f\"Depth {model[i].depth}: {model[i]}\" for i in range(len(model))]), sep=\"\\n\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_accuracy = evaluate(device, model, test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.2f}%, Test accuracy: {test_accuracy:.2f}%')\n",
    "    lr_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5981148 ],\n",
       "       [0.9634854 ],\n",
       "       [1.1180352 ],\n",
       "       [0.25245157],\n",
       "       [2.484147  ],\n",
       "       [1.161348  ],\n",
       "       [0.87380683],\n",
       "       [0.44336656],\n",
       "       [0.9320248 ],\n",
       "       [1.1274574 ],\n",
       "       [0.12749925],\n",
       "       [1.7562745 ],\n",
       "       [0.7457105 ],\n",
       "       [0.08640575],\n",
       "       [1.2357011 ],\n",
       "       [1.8209292 ],\n",
       "       [1.2359884 ],\n",
       "       [0.30162323],\n",
       "       [0.12449323],\n",
       "       [0.05077058],\n",
       "       [0.42775792],\n",
       "       [0.5930919 ],\n",
       "       [0.6066395 ],\n",
       "       [0.26709583],\n",
       "       [1.0321921 ],\n",
       "       [0.07010241],\n",
       "       [0.12023831],\n",
       "       [0.1930366 ],\n",
       "       [1.2029365 ],\n",
       "       [0.21384852],\n",
       "       [0.667683  ],\n",
       "       [0.22509019],\n",
       "       [0.97664076],\n",
       "       [0.33046725],\n",
       "       [1.3761361 ],\n",
       "       [0.6719827 ],\n",
       "       [0.3749767 ],\n",
       "       [0.51912063],\n",
       "       [2.6440165 ],\n",
       "       [0.3438414 ],\n",
       "       [0.44473463],\n",
       "       [0.35270986],\n",
       "       [0.8643006 ],\n",
       "       [0.46024805],\n",
       "       [0.7238416 ],\n",
       "       [1.5828304 ],\n",
       "       [1.4176172 ],\n",
       "       [0.28053018],\n",
       "       [0.47170863],\n",
       "       [1.2234609 ],\n",
       "       [0.50784916],\n",
       "       [0.2045496 ],\n",
       "       [0.7511464 ],\n",
       "       [2.2519631 ],\n",
       "       [0.53807163],\n",
       "       [0.18482922],\n",
       "       [1.0371845 ],\n",
       "       [0.7920953 ],\n",
       "       [1.0215054 ],\n",
       "       [0.9137935 ],\n",
       "       [0.03120091],\n",
       "       [2.0445652 ],\n",
       "       [0.41222066],\n",
       "       [0.99777234],\n",
       "       [0.19569786],\n",
       "       [1.4346701 ],\n",
       "       [0.5884427 ],\n",
       "       [0.8527775 ],\n",
       "       [1.1589556 ],\n",
       "       [0.06320994],\n",
       "       [0.23740946],\n",
       "       [1.695517  ],\n",
       "       [0.73437613],\n",
       "       [1.1560967 ],\n",
       "       [0.54575336],\n",
       "       [0.4884792 ],\n",
       "       [0.14459895],\n",
       "       [0.3690647 ],\n",
       "       [0.8651468 ],\n",
       "       [0.778015  ],\n",
       "       [0.93204296],\n",
       "       [1.1930641 ],\n",
       "       [0.53393674],\n",
       "       [0.24493909],\n",
       "       [1.074556  ],\n",
       "       [2.1423216 ],\n",
       "       [0.8089287 ],\n",
       "       [1.55228   ],\n",
       "       [0.16377902],\n",
       "       [0.7034127 ],\n",
       "       [0.09425773],\n",
       "       [1.121094  ],\n",
       "       [0.3372933 ],\n",
       "       [0.53050864],\n",
       "       [0.5872485 ],\n",
       "       [0.6916148 ],\n",
       "       [0.47560677],\n",
       "       [0.7894868 ],\n",
       "       [1.4552455 ],\n",
       "       [1.3207943 ],\n",
       "       [1.576813  ],\n",
       "       [0.6690262 ],\n",
       "       [2.5116918 ],\n",
       "       [0.6993155 ],\n",
       "       [0.07243504],\n",
       "       [0.4027928 ],\n",
       "       [0.03596292],\n",
       "       [1.0209202 ],\n",
       "       [0.42574608],\n",
       "       [0.34751523],\n",
       "       [1.287222  ],\n",
       "       [0.9133664 ],\n",
       "       [0.228193  ],\n",
       "       [0.22320612],\n",
       "       [1.4524608 ],\n",
       "       [0.57388884],\n",
       "       [1.3554044 ],\n",
       "       [1.1602938 ],\n",
       "       [1.9208887 ],\n",
       "       [1.4232796 ],\n",
       "       [0.6460886 ],\n",
       "       [0.4586695 ],\n",
       "       [0.7327422 ],\n",
       "       [1.042147  ],\n",
       "       [1.0741682 ],\n",
       "       [0.0640603 ],\n",
       "       [1.0612597 ],\n",
       "       [0.1775695 ],\n",
       "       [2.018416  ],\n",
       "       [0.60332924],\n",
       "       [1.1085734 ],\n",
       "       [1.0403162 ],\n",
       "       [1.4402299 ],\n",
       "       [0.26818538],\n",
       "       [0.07688841],\n",
       "       [0.56014514],\n",
       "       [0.8123944 ],\n",
       "       [0.01805807],\n",
       "       [1.1996312 ],\n",
       "       [1.207614  ],\n",
       "       [0.59501743],\n",
       "       [0.39193186],\n",
       "       [0.560128  ],\n",
       "       [0.52633315],\n",
       "       [1.4703368 ],\n",
       "       [0.01261687],\n",
       "       [0.6666628 ],\n",
       "       [0.7889252 ],\n",
       "       [0.1775695 ],\n",
       "       [0.930572  ],\n",
       "       [1.1527754 ],\n",
       "       [0.9446422 ],\n",
       "       [0.57017314],\n",
       "       [0.5061317 ],\n",
       "       [1.5567933 ],\n",
       "       [0.3890073 ],\n",
       "       [1.1896926 ],\n",
       "       [0.22254352],\n",
       "       [0.3779905 ],\n",
       "       [1.392532  ],\n",
       "       [0.10936603],\n",
       "       [0.28346473],\n",
       "       [0.27952614],\n",
       "       [0.30967483],\n",
       "       [0.8877983 ],\n",
       "       [1.0146838 ],\n",
       "       [0.56167877],\n",
       "       [0.12194374],\n",
       "       [0.33555678],\n",
       "       [0.48301175],\n",
       "       [0.17589402],\n",
       "       [0.9133664 ],\n",
       "       [3.136038  ],\n",
       "       [0.9940765 ],\n",
       "       [0.13363504],\n",
       "       [2.2219634 ],\n",
       "       [1.97149   ],\n",
       "       [0.05064965],\n",
       "       [0.6725232 ],\n",
       "       [1.1178315 ],\n",
       "       [0.37686482],\n",
       "       [1.5633483 ],\n",
       "       [0.5267799 ],\n",
       "       [0.4258197 ],\n",
       "       [1.034227  ],\n",
       "       [0.55753845],\n",
       "       [1.5645511 ],\n",
       "       [0.9010264 ],\n",
       "       [0.55299866],\n",
       "       [0.9640119 ],\n",
       "       [1.5734146 ],\n",
       "       [1.7805357 ],\n",
       "       [1.4475883 ],\n",
       "       [0.21543406],\n",
       "       [0.34803212],\n",
       "       [0.8963098 ],\n",
       "       [0.20717287],\n",
       "       [1.0394332 ],\n",
       "       [0.1775695 ],\n",
       "       [1.7986577 ],\n",
       "       [1.9142076 ],\n",
       "       [1.0908751 ],\n",
       "       [1.1357872 ],\n",
       "       [0.44622457],\n",
       "       [0.8096691 ],\n",
       "       [1.2675534 ],\n",
       "       [0.59504235],\n",
       "       [1.0145636 ],\n",
       "       [1.4249876 ],\n",
       "       [1.514438  ],\n",
       "       [0.13732429],\n",
       "       [1.3617759 ],\n",
       "       [0.3521906 ],\n",
       "       [0.57723355],\n",
       "       [0.08985323],\n",
       "       [3.0772026 ],\n",
       "       [0.63465965],\n",
       "       [0.30708033],\n",
       "       [0.3627165 ],\n",
       "       [1.97149   ],\n",
       "       [0.64237463],\n",
       "       [1.2600849 ],\n",
       "       [1.0624195 ],\n",
       "       [1.7796872 ],\n",
       "       [0.768236  ],\n",
       "       [0.12132883],\n",
       "       [1.1736423 ],\n",
       "       [0.24950922],\n",
       "       [0.8920729 ],\n",
       "       [1.7750767 ],\n",
       "       [0.43655518],\n",
       "       [1.1984861 ],\n",
       "       [0.50459594],\n",
       "       [0.96194965],\n",
       "       [0.57226354],\n",
       "       [1.6398058 ],\n",
       "       [1.643845  ],\n",
       "       [1.4081545 ],\n",
       "       [0.29326728],\n",
       "       [1.7232093 ],\n",
       "       [0.6098047 ],\n",
       "       [0.32941854],\n",
       "       [1.953321  ],\n",
       "       [0.29289347],\n",
       "       [1.1071558 ],\n",
       "       [0.6211758 ],\n",
       "       [1.2004658 ],\n",
       "       [0.09378791],\n",
       "       [0.32033768],\n",
       "       [0.03670176],\n",
       "       [3.7366617 ],\n",
       "       [0.08468546],\n",
       "       [0.4667275 ],\n",
       "       [0.7361483 ],\n",
       "       [0.07269607],\n",
       "       [0.67573196]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [torch.randn(16,256) for i in range(5)]\n",
    "\n",
    "layers = np.array([np.array(i.flatten()) for i in layers]).flatten()\n",
    "mask = layers > 0\n",
    "layers = layers[mask]\n",
    "\n",
    "res = layers[np.random.randint(0, high = len(layers), size = 256)].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 74\u001b[0m\n\u001b[1;32m     70\u001b[0m layers \u001b[39m=\u001b[39m extract_activations_per_sample(extract_activations_layers(layers))\n\u001b[1;32m     71\u001b[0m layers \u001b[39m=\u001b[39m [l[l \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m layers]\n\u001b[0;32m---> 74\u001b[0m [random\u001b[39m.\u001b[39;49mchoice(l) \u001b[39mfor\u001b[39;49;00m l \u001b[39min\u001b[39;49;00m layers]\n\u001b[1;32m     76\u001b[0m \u001b[39m# res = layers[np.random.randint(0, high = layers.shape[0]-1, size = 256)].reshape(-1, 1)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39m# return torch.from_numpy(np.array(res, dtype=\"float32\"))\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[39m# wd(layers).shape\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 74\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m layers \u001b[39m=\u001b[39m extract_activations_per_sample(extract_activations_layers(layers))\n\u001b[1;32m     71\u001b[0m layers \u001b[39m=\u001b[39m [l[l \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m layers]\n\u001b[0;32m---> 74\u001b[0m [random\u001b[39m.\u001b[39;49mchoice(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m layers]\n\u001b[1;32m     76\u001b[0m \u001b[39m# res = layers[np.random.randint(0, high = layers.shape[0]-1, size = 256)].reshape(-1, 1)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39m# return torch.from_numpy(np.array(res, dtype=\"float32\"))\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[39m# wd(layers).shape\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/jax/lib/python3.11/random.py:369\u001b[0m, in \u001b[0;36mRandom.choice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchoice\u001b[39m(\u001b[39mself\u001b[39m, seq):\n\u001b[1;32m    368\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m seq:\n\u001b[1;32m    370\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot choose from an empty sequence\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    371\u001b[0m     \u001b[39mreturn\u001b[39;00m seq[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_randbelow(\u001b[39mlen\u001b[39m(seq))]\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_activations_layers(layers):\n",
    "    \"\"\" Extract for each layer the activations\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (layer_activation, batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return np.array([np.array([np.array(h) for h in l]) for l in layers])\n",
    "\n",
    "def extract_activations_per_sample(layers, mask = False):\n",
    "    \"\"\" Extract for each sample the activations \n",
    "    for each layer and store them in a list.\n",
    "\n",
    "    Args:\n",
    "        layers (np.array): shape (layer_activation, batch_size, number_of_neurons)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    if mask == True:\n",
    "        # mask the activations to remove zeros\n",
    "        mask = layers != 0\n",
    "        layers = [[np.array(h[m]) for h, m in zip(l,sm)] \n",
    "                for l, sm in zip(layers, mask)]\n",
    "        \n",
    "    return np.array([layers[:,i,:].flatten().reshape(-1, 1) for i in range(layers.shape[1])])\n",
    "\n",
    "\n",
    "def get_sampled_activations(activations, bandwidth = 0.2):\n",
    "    \"\"\" Sample the activations using KDE\n",
    "\n",
    "    Args:\n",
    "        activations (np.array): shape (batch_size, number_of_activations)\n",
    "\n",
    "    Returns:\n",
    "        np.array: shape (batch_size, number_of_activations)\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.from_numpy(np.array([KernelDensity(kernel=\"gaussian\", bandwidth=bandwidth).fit(a).sample([64]) for a in activations], dtype=\"float32\")).squeeze(2)\n",
    "\n",
    "def wd(layers: list()):\n",
    "    \"\"\" Compute the weight decay for each layer\n",
    "\n",
    "    Args:\n",
    "        layers (list): list of layers\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor: weight decay\n",
    "\n",
    "    \"\"\"\n",
    "    return get_sampled_activations(\n",
    "                list(\n",
    "                    extract_activations_per_sample(\n",
    "                            extract_activations_layers(layers), \n",
    "                            mask=False\n",
    "                        )\n",
    "                ), \n",
    "                bandwidth=0.2\n",
    "            )\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "layers = [torch.randn(64,5) for i in range(5)]\n",
    "\n",
    "layers = extract_activations_per_sample(extract_activations_layers(layers))\n",
    "layers = [l[l < 0] for l in layers]\n",
    "\n",
    "\n",
    "[random.choice(l) for l in layers]\n",
    "\n",
    "# res = layers[np.random.randint(0, high = layers.shape[0]-1, size = 256)].reshape(-1, 1)\n",
    "# return torch.from_numpy(np.array(res, dtype=\"float32\"))\n",
    "\n",
    "\n",
    "# wd(layers).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1/10, Training Loss: 1.8164, Training Accuracy: 33.93%, Test accuracy: 39.72%\n",
      "Epoch 2/10, Training Loss: 1.6439, Training Accuracy: 40.74%, Test accuracy: 41.99%\n",
      "Epoch 3/10, Training Loss: 1.5454, Training Accuracy: 44.20%, Test accuracy: 42.73%\n",
      "Epoch 4/10, Training Loss: 1.4934, Training Accuracy: 45.90%, Test accuracy: 44.51%\n",
      "Epoch 5/10, Training Loss: 1.4409, Training Accuracy: 48.04%, Test accuracy: 49.23%\n",
      "Epoch 6/10, Training Loss: 1.4050, Training Accuracy: 49.34%, Test accuracy: 47.79%\n",
      "Epoch 7/10, Training Loss: 1.3646, Training Accuracy: 50.74%, Test accuracy: 48.76%\n",
      "Epoch 8/10, Training Loss: 1.3404, Training Accuracy: 51.69%, Test accuracy: 48.74%\n",
      "Epoch 9/10, Training Loss: 1.3010, Training Accuracy: 53.03%, Test accuracy: 49.75%\n",
      "Epoch 10/10, Training Loss: 1.2674, Training Accuracy: 54.31%, Test accuracy: 49.79%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = nn.Linear(3072, 256)\n",
    "        self.l2 = nn.Linear(256, 256)\n",
    "        self.l3 = nn.Linear(256, 256)\n",
    "        self.l4 = nn.Linear(256, 10)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        repr = []\n",
    "        x = self.flatten(x)\n",
    "        x = self.gelu(self.l1(x))\n",
    "        x = self.gelu(self.l2(x))\n",
    "        x = self.gelu(self.l3(x))\n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = MLP().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_accuracy = evaluate(device, model, test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.2f}%, Test accuracy: {test_accuracy:.2f}%')\n",
    "    lr_scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
